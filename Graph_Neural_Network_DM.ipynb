{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g2oNlB2Ezfal",
        "sJrpd0OOxknK",
        "u3nN9LjOZGxa"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNGG8UKjrfRB1eMXBqUofQV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beekiran00/DeepMirror-Task-ML-Engineer---Bhanu-Velpula/blob/main/Graph_Neural_Network_DM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading and Importing Libraries"
      ],
      "metadata": {
        "id": "g2oNlB2Ezfal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit\n",
        "!pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.0+cpu.html\n",
        "!pip install PyTDC\n",
        "!pip install deepchem\n",
        "!pip install dgl\n",
        "!pip install dgllife\n",
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGqScmlHxDH8",
        "outputId": "fd7f835c-4756-4771-bb10-ebc0fc2f4a43"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.8/dist-packages (2022.9.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rdkit) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cpu.html\n",
            "Requirement already satisfied: pyg-lib in /usr/local/lib/python3.8/dist-packages (0.1.0+pt113cpu)\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.8/dist-packages (2.1.0+pt113cpu)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.8/dist-packages (0.6.15+pt113cpu)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.8/dist-packages (1.6.0+pt113cpu)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.8/dist-packages (1.2.1+pt113cpu)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.8/dist-packages (2.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (0.24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (5.9.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyTDC in /usr/local/lib/python3.8/dist-packages (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from PyTDC) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from PyTDC) (1.21.6)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from PyTDC) (0.11.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from PyTDC) (4.64.1)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.8/dist-packages (from PyTDC) (0.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from PyTDC) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from PyTDC) (0.24.2)\n",
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.8/dist-packages (from PyTDC) (2022.9.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->PyTDC) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->PyTDC) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->PyTDC) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit-pypi->PyTDC) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->PyTDC) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->PyTDC) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->PyTDC) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->PyTDC) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->PyTDC) (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->PyTDC) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->PyTDC) (3.1.0)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.8/dist-packages (from seaborn->PyTDC) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn->PyTDC) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn->PyTDC) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn->PyTDC) (1.4.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deepchem in /usr/local/lib/python3.8/dist-packages (2.7.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.2.0)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.8/dist-packages (from deepchem) (2022.9.3)\n",
            "Requirement already satisfied: scipy<1.9 in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from deepchem) (0.24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepchem) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit->deepchem) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->deepchem) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.8/dist-packages (0.9.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.7.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (5.9.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl) (2.8.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from dgl) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dgllife in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from dgllife) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from dgllife) (1.21.6)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgllife) (2.8.8)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.8/dist-packages (from dgllife) (0.1.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dgllife) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn<1.0,>=0.22.2 in /usr/local/lib/python3.8/dist-packages (from dgllife) (0.24.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from dgllife) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from dgllife) (1.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from dgllife) (1.3.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->dgllife) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->dgllife) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->dgllife) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->dgllife) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.0,>=0.22.2->dgllife) (3.1.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.8/dist-packages (from hyperopt->dgllife) (4.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from hyperopt->dgllife) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from hyperopt->dgllife) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->dgllife) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->dgllife) (2.8.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from pymongo->hyperopt->dgllife) (2.2.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[K     |████████████████████████████████| 512 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NTK2tYcowyRo"
      },
      "outputs": [],
      "source": [
        "# IMPORT THE NECESSARY LIBRARIES\n",
        "\n",
        "# BASIC PANDAS AND NUMPY, matplotlib libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from IPython.display import Javascript\n",
        "import time\n",
        "\n",
        "# RDkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
        "\n",
        "# DEEPCHEM\n",
        "import deepchem as dc\n",
        "from deepchem.models import GraphConvModel\n",
        "\n",
        "# Tensorflow\n",
        "from tensorflow.python import train\n",
        "\n",
        "# SKLEARN and sklearn metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Pytorch and Pytorch Geometric\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torchmetrics.classification import AUROC\n",
        "from torchmetrics.classification import ROC\n",
        "from torchmetrics.classification import Precision\n",
        "from torchmetrics.classification import Specificity\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "sJrpd0OOxknK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tdc.single_pred import ADME\n",
        "data = ADME(name = 'HIA_Hou')\n",
        "split = data.get_split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNAy6_ijw7jr",
        "outputId": "34943d72-47c4-41bd-e461-949f072cbd38"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "100%|██████████| 40.1k/40.1k [00:00<00:00, 10.8MiB/s]\n",
            "Loading...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viewing the dataset, the dataset is in the form of a dictionary, train: values, valid: values and test: values"
      ],
      "metadata": {
        "id": "oObok1Mjx6PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split"
      ],
      "metadata": {
        "id": "X2EbDhNFxoL1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset type: \", type(data))\n",
        "print(split.keys())\n",
        "#print(split.values())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucctdr-9x2Vf",
        "outputId": "f6207a06-2b5d-445a-ecf3-0bf398b7fc99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset type:  <class 'tdc.single_pred.adme.ADME'>\n",
            "dict_keys(['train', 'valid', 'test'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame.from_dict(split['train'])\n",
        "train_df\n",
        "valid_df = pd.DataFrame.from_dict(split['valid'])\n",
        "#valid_df\n",
        "test_df = pd.DataFrame.from_dict(split['test'])\n",
        "#test_df\n",
        "\n",
        "# ^ converting the dict to a dataframe of train valid and test"
      ],
      "metadata": {
        "id": "ejxdoja0yKZd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Neural Network Class"
      ],
      "metadata": {
        "id": "9yYJ60EeQ5ma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMILES to GRAPH\n"
      ],
      "metadata": {
        "id": "r-Q4MsrSqkum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the dataset only has the SMILES String under the column 'Drug', we have to extract features fromthe SMILES String, only problem is, unlike normal mehtods for feature extraction from SMILES, graph neural networks takes a graph structure, and this is a graph level task. Therefore, the firest step would be to take the dataset as input, and convert them to graph data"
      ],
      "metadata": {
        "id": "Fgt_SvfOqu8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In summary, the functions below converts a given smiles string, into a graph data format, which is used in Pytorch GNN model."
      ],
      "metadata": {
        "id": "wqaUPocRrQmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(x, permitted_list):\n",
        "    \"\"\"\n",
        "    Maps input elements x which are not in the permitted list to the last element\n",
        "    of the permitted list.\n",
        "    \"\"\"\n",
        "\n",
        "    if x not in permitted_list:\n",
        "        x = permitted_list[-1]\n",
        "\n",
        "    binary_encoding = [int(boolean_value) for boolean_value in list(map(lambda s: x == s, permitted_list))]\n",
        "\n",
        "    return binary_encoding"
      ],
      "metadata": {
        "id": "q3zZXKHoTjrN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_atom_features(atom, \n",
        "                      use_chirality = True, \n",
        "                      hydrogens_implicit = True):\n",
        "    \"\"\"\n",
        "    Takes an RDKit atom object as input and gives a 1d-numpy array of atom features as output.\n",
        "    \"\"\"\n",
        "\n",
        "    # define list of permitted atoms\n",
        "    \n",
        "    permitted_list_of_atoms =  ['C','N','O','S','F','Si','P','Cl','Br','Mg','Na','Ca','Fe','As','Al','I', 'B','V','K','Tl','Yb','Sb','Sn','Ag','Pd','Co','Se','Ti','Zn', 'Li','Ge','Cu','Au','Ni','Cd','In','Mn','Zr','Cr','Pt','Hg','Pb','Unknown']\n",
        "    \n",
        "    if hydrogens_implicit == False:\n",
        "        permitted_list_of_atoms = ['H'] + permitted_list_of_atoms\n",
        "    \n",
        "    # compute atom features\n",
        "    \n",
        "    atom_type_enc = one_hot_encoding(str(atom.GetSymbol()), permitted_list_of_atoms)\n",
        "    \n",
        "    n_heavy_neighbors_enc = one_hot_encoding(int(atom.GetDegree()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n",
        "    \n",
        "    formal_charge_enc = one_hot_encoding(int(atom.GetFormalCharge()), [-3, -2, -1, 0, 1, 2, 3, \"Extreme\"])\n",
        "    \n",
        "    hybridisation_type_enc = one_hot_encoding(str(atom.GetHybridization()), [\"S\", \"SP\", \"SP2\", \"SP3\", \"SP3D\", \"SP3D2\", \"OTHER\"])\n",
        "    \n",
        "    is_in_a_ring_enc = [int(atom.IsInRing())]\n",
        "    \n",
        "    is_aromatic_enc = [int(atom.GetIsAromatic())]\n",
        "    \n",
        "    atomic_mass_scaled = [float((atom.GetMass() - 10.812)/116.092)]\n",
        "    \n",
        "    vdw_radius_scaled = [float((Chem.GetPeriodicTable().GetRvdw(atom.GetAtomicNum()) - 1.5)/0.6)]\n",
        "    \n",
        "    covalent_radius_scaled = [float((Chem.GetPeriodicTable().GetRcovalent(atom.GetAtomicNum()) - 0.64)/0.76)]\n",
        "\n",
        "    atom_feature_vector = atom_type_enc + n_heavy_neighbors_enc + formal_charge_enc + hybridisation_type_enc + is_in_a_ring_enc + is_aromatic_enc + atomic_mass_scaled + vdw_radius_scaled + covalent_radius_scaled\n",
        "                                    \n",
        "    if use_chirality == True:\n",
        "        chirality_type_enc = one_hot_encoding(str(atom.GetChiralTag()), [\"CHI_UNSPECIFIED\", \"CHI_TETRAHEDRAL_CW\", \"CHI_TETRAHEDRAL_CCW\", \"CHI_OTHER\"])\n",
        "        atom_feature_vector += chirality_type_enc\n",
        "    \n",
        "    if hydrogens_implicit == True:\n",
        "        n_hydrogens_enc = one_hot_encoding(int(atom.GetTotalNumHs()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n",
        "        atom_feature_vector += n_hydrogens_enc\n",
        "\n",
        "    return np.array(atom_feature_vector)"
      ],
      "metadata": {
        "id": "L3gZkDhtTfuH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bond_features(bond, \n",
        "                      use_stereochemistry = True):\n",
        "    \"\"\"\n",
        "    Takes an RDKit bond object as input and gives a 1d-numpy array of bond features as output.\n",
        "    \"\"\"\n",
        "\n",
        "    permitted_list_of_bond_types = [Chem.rdchem.BondType.SINGLE, Chem.rdchem.BondType.DOUBLE, Chem.rdchem.BondType.TRIPLE, Chem.rdchem.BondType.AROMATIC]\n",
        "\n",
        "    bond_type_enc = one_hot_encoding(bond.GetBondType(), permitted_list_of_bond_types)\n",
        "    \n",
        "    bond_is_conj_enc = [int(bond.GetIsConjugated())]\n",
        "    \n",
        "    bond_is_in_ring_enc = [int(bond.IsInRing())]\n",
        "    \n",
        "    bond_feature_vector = bond_type_enc + bond_is_conj_enc + bond_is_in_ring_enc\n",
        "    \n",
        "    if use_stereochemistry == True:\n",
        "        stereo_type_enc = one_hot_encoding(str(bond.GetStereo()), [\"STEREOZ\", \"STEREOE\", \"STEREOANY\", \"STEREONONE\"])\n",
        "        bond_feature_vector += stereo_type_enc\n",
        "\n",
        "    return np.array(bond_feature_vector)"
      ],
      "metadata": {
        "id": "GNNZjufrTe6l"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pytorch_geometric_graph_data_list_from_smiles_and_labels(x_smiles, y):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    \n",
        "    x_smiles = [smiles_1, smiles_2, ....] ... a list of SMILES strings\n",
        "    y = [y_1, y_2, ...] ... a list of numerial labels for the SMILES strings (such as associated pKi values)\n",
        "    \n",
        "    Outputs:\n",
        "    \n",
        "    data_list = [G_1, G_2, ...] ... a list of torch_geometric.data.Data objects which represent labeled molecular graphs that can readily be used for machine learning\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    data_list = []\n",
        "    \n",
        "    for (smiles, y_val) in zip(x_smiles, y):\n",
        "        \n",
        "        # convert SMILES to RDKit mol object\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "        # get feature dimensions\n",
        "        n_nodes = mol.GetNumAtoms()\n",
        "        n_edges = 2*mol.GetNumBonds()\n",
        "        unrelated_smiles = \"O=O\"\n",
        "        unrelated_mol = Chem.MolFromSmiles(unrelated_smiles)\n",
        "        n_node_features = len(get_atom_features(unrelated_mol.GetAtomWithIdx(0)))\n",
        "        n_edge_features = len(get_bond_features(unrelated_mol.GetBondBetweenAtoms(0,1)))\n",
        "\n",
        "        # construct node feature matrix X of shape (n_nodes, n_node_features)\n",
        "        X = np.zeros((n_nodes, n_node_features))\n",
        "\n",
        "        for atom in mol.GetAtoms():\n",
        "            X[atom.GetIdx(), :] = get_atom_features(atom)\n",
        "            \n",
        "        X = torch.tensor(X, dtype = torch.float)\n",
        "        \n",
        "        # construct edge index array E of shape (2, n_edges)\n",
        "        (rows, cols) = np.nonzero(GetAdjacencyMatrix(mol))\n",
        "        torch_rows = torch.from_numpy(rows.astype(np.int64)).to(torch.long)\n",
        "        torch_cols = torch.from_numpy(cols.astype(np.int64)).to(torch.long)\n",
        "        E = torch.stack([torch_rows, torch_cols], dim = 0)\n",
        "        \n",
        "        # construct edge feature array EF of shape (n_edges, n_edge_features)\n",
        "        EF = np.zeros((n_edges, n_edge_features))\n",
        "        \n",
        "        for (k, (i,j)) in enumerate(zip(rows, cols)):\n",
        "            \n",
        "            EF[k] = get_bond_features(mol.GetBondBetweenAtoms(int(i),int(j)))\n",
        "        \n",
        "        EF = torch.tensor(EF, dtype = torch.float)\n",
        "        \n",
        "        # construct label tensor\n",
        "        y_tensor = torch.tensor(np.array([y_val]), dtype = torch.float)\n",
        "        \n",
        "        # construct Pytorch Geometric data object and append to data list\n",
        "        data_list.append(Data(x = X, edge_index = E, edge_attr = EF, y = y_tensor))\n",
        "\n",
        "    return data_list"
      ],
      "metadata": {
        "id": "P2R-7F95S6-L"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've written our functions, the next step is to pass the datasets to turn them into graphs"
      ],
      "metadata": {
        "id": "VlWhze-xriBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# turn train dataset into a graph\n",
        "train_dataset = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(train_df[\"Drug\"], train_df[\"Y\"])\n",
        "#turn valid dataset into a graph\n",
        "valid_dataset = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(valid_df[\"Drug\"], valid_df[\"Y\"])\n",
        "#turn test dataset into a graph\n",
        "test_dataset = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(test_df[\"Drug\"], test_df[\"Y\"])"
      ],
      "metadata": {
        "id": "pT7Rn-yBS9i3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The output of the dataset is in terms of a list, but the values inside the list are graph objects.\n",
        "type(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlMLDmDdTux3",
        "outputId": "c747738e-5ca6-46c8-b7a9-1a6099bc031a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data using pytorch dataloader\n",
        "\n",
        "# Data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset\n",
        "graph_train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) # train dataset into dataloader\n",
        "graph_val_loader = DataLoader(valid_dataset, batch_size=64) # Additional loader if you want to change to a larger dataset\n",
        "graph_test_loader = DataLoader(test_dataset, batch_size=64) # test dataset into dataloader"
      ],
      "metadata": {
        "id": "ILttvgSrcUXY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(graph_test_loader) # we have a torch object"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf79JK0beGhc",
        "outputId": "0fd7f58c-9308-47b5-dde6-329c7e1f59be"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch_geometric.loader.dataloader.DataLoader object at 0x7fbda55ba1f0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(graph_test_loader))\n",
        "print(\"Batch:\", batch)\n",
        "print(\"Labels:\", batch.y[:10])\n",
        "print(\"Batch indices:\", batch.batch[:40])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5MUhs3MeI-i",
        "outputId": "68cd838d-e15e-4eec-8384-07270b3e363c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: DataBatch(x=[1466, 79], edge_index=[2, 3124], edge_attr=[3124, 10], y=[64], batch=[1466], ptr=[65])\n",
            "Labels: tensor([1., 0., 1., 1., 1., 1., 1., 1., 0., 1.])\n",
            "Batch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view the number of graphs and the batch size\n",
        "for step, data in enumerate(graph_train_loader):\n",
        "    print(f'Step {step + 1}:')\n",
        "    print('=======')\n",
        "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
        "    print(data)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDgYTv82hVZS",
        "outputId": "eca28cf1-b845-4668-c157-79e38762476f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[1384, 79], edge_index=[2, 2980], edge_attr=[2980, 10], y=[64], batch=[1384], ptr=[65])\n",
            "\n",
            "Step 2:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[1498, 79], edge_index=[2, 3192], edge_attr=[3192, 10], y=[64], batch=[1498], ptr=[65])\n",
            "\n",
            "Step 3:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[1567, 79], edge_index=[2, 3368], edge_attr=[3368, 10], y=[64], batch=[1567], ptr=[65])\n",
            "\n",
            "Step 4:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[1549, 79], edge_index=[2, 3332], edge_attr=[3332, 10], y=[64], batch=[1549], ptr=[65])\n",
            "\n",
            "Step 5:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[1337, 79], edge_index=[2, 2864], edge_attr=[2864, 10], y=[64], batch=[1337], ptr=[65])\n",
            "\n",
            "Step 6:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "DataBatch(x=[1476, 79], edge_index=[2, 3186], edge_attr=[3186, 10], y=[64], batch=[1476], ptr=[65])\n",
            "\n",
            "Step 7:\n",
            "=======\n",
            "Number of graphs in the current batch: 20\n",
            "DataBatch(x=[488, 79], edge_index=[2, 1038], edge_attr=[1038, 10], y=[20], batch=[488], ptr=[21])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combine the dataset to get the number of features, this input goes into the pytorch GNN model later\n",
        "dataset = []\n",
        "dataset.append(train_dataset)\n",
        "dataset.append(valid_dataset)\n",
        "dataset.append(test_dataset)\n"
      ],
      "metadata": {
        "id": "qOnXewnQjY5_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the num_node_features, since the graph data is inside a list of list\n",
        "sum=0\n",
        "for i in dataset:\n",
        "  for j in i:\n",
        "    num = j.num_node_features\n",
        "    print(num)\n",
        "    sum +=num\n",
        "print(sum)\n",
        "\n",
        "# the num_node features is 79\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J158-t2UirBY",
        "outputId": "24881708-ef69-49bd-8cf4-4fe46ef0325c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "79\n",
            "45662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(79, hidden_channels) # define first convolution\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels) # define the second convolution\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels) # define the third convolution\n",
        "        self.lin = Linear(hidden_channels, 2)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # 1. Obtain node embeddings \n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return x\n",
        "# call the model and print the model, its convolutions\n",
        "model = GCN(hidden_channels=64)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-ItsXeFfR9E",
        "outputId": "2f213a74-d7fb-46d5-e0c6-d71d2eb87e62"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(79, 64)\n",
            "  (conv2): GCNConv(64, 64)\n",
            "  (conv3): GCNConv(64, 64)\n",
            "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# misc to display output\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "# call the model class we created for the Graph Neural Networks\n",
        "model = GCN(hidden_channels=64)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # initalise the optimiser, we used ADAM optimiser with learing rate lr = 0.01\n",
        "criterion = torch.nn.CrossEntropyLoss() #initialise the criterion, CrossEntropyLoss used here\n",
        "\n",
        "# define the train and test models\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    for data in graph_train_loader:  # Iterate in batches over the training dataset.\n",
        "         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
        "         loss = criterion(out, data.y.type(torch.LongTensor))  # Compute the loss.\n",
        "         loss.backward()  # Derive gradients.\n",
        "         optimizer.step()  # Update parameters based on gradients.\n",
        "         optimizer.zero_grad()  # Clear gradients.\n",
        "\n",
        "def test(loader):\n",
        "     model.eval()\n",
        "     CM=0\n",
        "\n",
        "     correct = 0\n",
        "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
        "         out = model(data.x, data.edge_index, data.batch)  \n",
        "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "         correct += int((pred == data.y).sum()) \n",
        "         auroc = AUROC(task=\"binary\")\n",
        "         au_roc_score = auroc(pred, data.y) # gets the roc_auc score of the model\n",
        "         precision = Precision(task=\"binary\", average='macro', num_classes=3)\n",
        "         precision_score = precision(pred, data.y) # gets the precision of the model\n",
        "         specificity = Specificity(task=\"binary\", average='macro', num_classes=3)\n",
        "         spec_score = specificity(pred, data.y) # gets hte specificity of the model\n",
        "         \n",
        "         \n",
        "            \n",
        "     return correct / len(loader.dataset), au_roc_score, precision_score, spec_score # Derive ratio of correct predictions.\n",
        "\n",
        "start_time = time.time()\n",
        "# For loop to train and test the model for 170 epochs\n",
        "for epoch in range(1, 171):\n",
        "   \n",
        "    train()\n",
        "    train_acc = test(graph_train_loader)\n",
        "    test_acc = test(graph_test_loader)\n",
        "\n",
        "    # print the epoch number and metrics\n",
        "    print(f'Epoch: {epoch:03d}',train_acc, test_acc)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "VsJ3I4kuikId",
        "outputId": "d78f534b-f8cf-4b81-bead-7a73a1afd2cc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001 (0.8688118811881188, tensor(0.5000), tensor(0.9500), tensor(0.)) (0.8362068965517241, tensor(0.5000), tensor(0.8077), tensor(0.))\n",
            "Epoch: 002 (0.8688118811881188, tensor(0.5000), tensor(0.7500), tensor(0.)) (0.8362068965517241, tensor(0.5000), tensor(0.8077), tensor(0.))\n",
            "Epoch: 003 (0.8688118811881188, tensor(0.5000), tensor(0.9500), tensor(0.)) (0.8362068965517241, tensor(0.5000), tensor(0.8077), tensor(0.))\n",
            "Epoch: 004 (0.8688118811881188, tensor(0.5000), tensor(0.9500), tensor(0.)) (0.8362068965517241, tensor(0.5000), tensor(0.8077), tensor(0.))\n",
            "Epoch: 005 (0.8910891089108911, tensor(0.5000), tensor(0.9500), tensor(0.)) (0.8706896551724138, tensor(0.6500), tensor(0.8571), tensor(0.3000))\n",
            "Epoch: 006 (0.8935643564356436, tensor(0.6250), tensor(0.8421), tensor(0.2500)) (0.8706896551724138, tensor(0.6500), tensor(0.8571), tensor(0.3000))\n",
            "Epoch: 007 (0.8910891089108911, tensor(0.7222), tensor(0.9444), tensor(0.5000)) (0.9051724137931034, tensor(0.7000), tensor(0.8750), tensor(0.4000))\n",
            "Epoch: 008 (0.8811881188118812, tensor(0.6000), tensor(0.7895), tensor(0.2000)) (0.8620689655172413, tensor(0.6000), tensor(0.8400), tensor(0.2000))\n",
            "Epoch: 009 (0.8960396039603961, tensor(0.8333), tensor(0.9444), tensor(0.6667)) (0.8793103448275862, tensor(0.7000), tensor(0.8750), tensor(0.4000))\n",
            "Epoch: 010 (0.900990099009901, tensor(0.6667), tensor(0.8947), tensor(0.3333)) (0.9137931034482759, tensor(0.8000), tensor(0.9130), tensor(0.6000))\n",
            "Epoch: 011 (0.9158415841584159, tensor(0.7667), tensor(0.8750), tensor(0.6000)) (0.9310344827586207, tensor(0.8500), tensor(0.9333), tensor(0.7000))\n",
            "Epoch: 012 (0.9034653465346535, tensor(0.5000), tensor(0.8500), tensor(0.)) (0.8879310344827587, tensor(0.7500), tensor(0.8936), tensor(0.5000))\n",
            "Epoch: 013 (0.9183168316831684, tensor(0.5000), tensor(0.8000), tensor(0.)) (0.896551724137931, tensor(0.7500), tensor(0.8936), tensor(0.5000))\n",
            "Epoch: 014 (0.9183168316831684, tensor(0.5000), tensor(0.9500), tensor(0.)) (0.896551724137931, tensor(0.7500), tensor(0.8936), tensor(0.5000))\n",
            "Epoch: 015 (0.943069306930693, tensor(0.9688), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.8643), tensor(0.9512), tensor(0.8000))\n",
            "Epoch: 016 (0.9603960396039604, tensor(0.), tensor(1.), tensor(0.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 017 (0.9603960396039604, tensor(0.8000), tensor(0.8824), tensor(0.6000)) (0.9396551724137931, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 018 (0.9554455445544554, tensor(0.9000), tensor(0.9375), tensor(0.8000)) (0.9051724137931034, tensor(0.8500), tensor(0.9333), tensor(0.7000))\n",
            "Epoch: 019 (0.9554455445544554, tensor(0.9722), tensor(1.), tensor(1.)) (0.9137931034482759, tensor(0.8500), tensor(0.9333), tensor(0.7000))\n",
            "Epoch: 020 (0.9653465346534653, tensor(0.7500), tensor(0.9474), tensor(0.5000)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 021 (0.9727722772277227, tensor(0.9474), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 022 (0.9727722772277227, tensor(0.9412), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 023 (0.9702970297029703, tensor(0.9706), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 024 (0.9628712871287128, tensor(0.), tensor(1.), tensor(0.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 025 (0.9727722772277227, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 026 (0.9777227722772277, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 027 (0.9777227722772277, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 028 (0.9801980198019802, tensor(0.), tensor(1.), tensor(0.)) (0.9396551724137931, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 029 (0.9702970297029703, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 030 (0.9504950495049505, tensor(0.6250), tensor(0.8421), tensor(0.2500)) (0.896551724137931, tensor(0.7500), tensor(0.8936), tensor(0.5000))\n",
            "Epoch: 031 (0.9826732673267327, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 032 (0.9727722772277227, tensor(0.9722), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 033 (0.9504950495049505, tensor(0.7500), tensor(0.9474), tensor(0.5000)) (0.896551724137931, tensor(0.7500), tensor(0.8936), tensor(0.5000))\n",
            "Epoch: 034 (0.9777227722772277, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 035 (0.9777227722772277, tensor(0.7188), tensor(0.8824), tensor(0.5000)) (0.9396551724137931, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 036 (0.9801980198019802, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 037 (0.9801980198019802, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 038 (0.9851485148514851, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 039 (0.9727722772277227, tensor(1.), tensor(1.), tensor(1.)) (0.9224137931034483, tensor(0.8500), tensor(0.9333), tensor(0.7000))\n",
            "Epoch: 040 (0.9777227722772277, tensor(0.9444), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 041 (0.9752475247524752, tensor(0.9722), tensor(1.), tensor(1.)) (0.9224137931034483, tensor(0.8500), tensor(0.9333), tensor(0.7000))\n",
            "Epoch: 042 (0.9455445544554455, tensor(0.9474), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8762), tensor(0.9524), tensor(0.8000))\n",
            "Epoch: 043 (0.9579207920792079, tensor(1.), tensor(1.), tensor(1.)) (0.9137931034482759, tensor(0.8500), tensor(0.9333), tensor(0.7000))\n",
            "Epoch: 044 (0.9851485148514851, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 045 (0.9777227722772277, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 046 (0.9826732673267327, tensor(0.9722), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 047 (0.9876237623762376, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 048 (0.9851485148514851, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 049 (0.9925742574257426, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.8762), tensor(0.9524), tensor(0.8000))\n",
            "Epoch: 050 (0.9777227722772277, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 051 (0.9876237623762376, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 052 (0.9876237623762376, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 053 (0.9900990099009901, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 054 (0.9900990099009901, tensor(0.8333), tensor(0.9444), tensor(0.6667)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 055 (0.9900990099009901, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 056 (0.9900990099009901, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 057 (0.9900990099009901, tensor(0.5000), tensor(0.9500), tensor(0.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 058 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 059 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 060 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 061 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 062 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 063 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 064 (0.9900990099009901, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.8381), tensor(0.9318), tensor(0.7000))\n",
            "Epoch: 065 (0.9678217821782178, tensor(1.), tensor(1.), tensor(1.)) (0.9224137931034483, tensor(0.8500), tensor(0.9333), tensor(0.7000))\n",
            "Epoch: 066 (0.995049504950495, tensor(0.8750), tensor(0.9412), tensor(0.7500)) (0.9310344827586207, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 067 (0.9133663366336634, tensor(0.9375), tensor(1.), tensor(1.)) (0.9137931034482759, tensor(0.9524), tensor(1.), tensor(1.))\n",
            "Epoch: 068 (0.9900990099009901, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 069 (0.9777227722772277, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 070 (0.9876237623762376, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 071 (0.9826732673267327, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 072 (0.9801980198019802, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.9262), tensor(0.9756), tensor(0.9000))\n",
            "Epoch: 073 (0.9876237623762376, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 074 (0.9876237623762376, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 075 (0.9900990099009901, tensor(0.), tensor(1.), tensor(0.)) (0.9396551724137931, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 076 (0.9900990099009901, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 077 (0.9925742574257426, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 078 (0.9876237623762376, tensor(1.), tensor(1.), tensor(1.)) (0.9224137931034483, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 079 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.9262), tensor(0.9756), tensor(0.9000))\n",
            "Epoch: 080 (0.9876237623762376, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 081 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 082 (0.9925742574257426, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 083 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 084 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 085 (0.9925742574257426, tensor(0.8750), tensor(0.9412), tensor(0.7500)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 086 (0.9975247524752475, tensor(0.), tensor(1.), tensor(0.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 087 (0.9851485148514851, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.8381), tensor(0.9318), tensor(0.7000))\n",
            "Epoch: 088 (0.9678217821782178, tensor(1.), tensor(1.), tensor(1.)) (0.9051724137931034, tensor(0.9143), tensor(0.9750), tensor(0.9000))\n",
            "Epoch: 089 (0.9851485148514851, tensor(0.9000), tensor(0.9375), tensor(0.8000)) (0.9137931034482759, tensor(0.8381), tensor(0.9318), tensor(0.7000))\n",
            "Epoch: 090 (0.9851485148514851, tensor(1.), tensor(1.), tensor(1.)) (0.9568965517241379, tensor(0.9262), tensor(0.9756), tensor(0.9000))\n",
            "Epoch: 091 (0.9851485148514851, tensor(1.), tensor(1.), tensor(1.)) (0.9224137931034483, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 092 (0.9851485148514851, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.9262), tensor(0.9756), tensor(0.9000))\n",
            "Epoch: 093 (0.995049504950495, tensor(0.8750), tensor(0.9412), tensor(0.7500)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 094 (0.9752475247524752, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 095 (0.9900990099009901, tensor(0.9688), tensor(1.), tensor(1.)) (0.9568965517241379, tensor(0.9262), tensor(0.9756), tensor(0.9000))\n",
            "Epoch: 096 (0.9826732673267327, tensor(0.9722), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.9000), tensor(0.9545), tensor(0.8000))\n",
            "Epoch: 097 (0.9925742574257426, tensor(0.), tensor(1.), tensor(0.)) (0.9568965517241379, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 098 (0.9900990099009901, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 099 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 100 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 101 (0.9900990099009901, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 102 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 103 (0.9851485148514851, tensor(1.), tensor(1.), tensor(1.)) (0.9224137931034483, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 104 (0.9801980198019802, tensor(0.9737), tensor(1.), tensor(1.)) (0.9655172413793104, tensor(0.9762), tensor(1.), tensor(1.))\n",
            "Epoch: 105 (0.9801980198019802, tensor(0.8750), tensor(0.9412), tensor(0.7500)) (0.9137931034482759, tensor(0.8381), tensor(0.9318), tensor(0.7000))\n",
            "Epoch: 106 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 107 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 108 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 109 (0.995049504950495, tensor(0.), tensor(1.), tensor(0.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 110 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 111 (0.9975247524752475, tensor(0.), tensor(1.), tensor(0.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 112 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 113 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 114 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 115 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 116 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 117 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 118 (0.9975247524752475, tensor(0.), tensor(1.), tensor(0.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 119 (0.9851485148514851, tensor(0.8333), tensor(0.9444), tensor(0.6667)) (0.9224137931034483, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 120 (0.9900990099009901, tensor(1.), tensor(1.), tensor(1.)) (0.9568965517241379, tensor(0.9881), tensor(1.), tensor(1.))\n",
            "Epoch: 121 (0.9851485148514851, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 122 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 123 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 124 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 125 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 126 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 127 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 128 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 129 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 130 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 131 (0.9975247524752475, tensor(0.), tensor(1.), tensor(0.)) (0.9310344827586207, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 132 (0.9925742574257426, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 133 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 134 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 135 (0.9826732673267327, tensor(0.8333), tensor(0.9444), tensor(0.6667)) (0.9224137931034483, tensor(0.8381), tensor(0.9318), tensor(0.7000))\n",
            "Epoch: 136 (0.9826732673267327, tensor(0.9706), tensor(1.), tensor(1.)) (0.9224137931034483, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 137 (0.9579207920792079, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.9143), tensor(0.9750), tensor(0.9000))\n",
            "Epoch: 138 (0.9702970297029703, tensor(1.), tensor(1.), tensor(1.)) (0.9137931034482759, tensor(0.8381), tensor(0.9318), tensor(0.7000))\n",
            "Epoch: 139 (0.9777227722772277, tensor(1.), tensor(1.), tensor(1.)) (0.9482758620689655, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 140 (0.9851485148514851, tensor(1.), tensor(1.), tensor(1.)) (0.9224137931034483, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 141 (0.9900990099009901, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 142 (0.9925742574257426, tensor(1.), tensor(1.), tensor(1.)) (0.9137931034482759, tensor(0.8381), tensor(0.9318), tensor(0.7000))\n",
            "Epoch: 143 (0.995049504950495, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 144 (0.995049504950495, tensor(0.8039), tensor(0.9412), tensor(0.6667)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 145 (0.995049504950495, tensor(0.9688), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 146 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 147 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9224137931034483, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 148 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 149 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 150 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 151 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 152 (0.9975247524752475, tensor(0.), tensor(1.), tensor(0.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 153 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 154 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 155 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 156 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 157 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 158 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 159 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 160 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 161 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 162 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 163 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 164 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 165 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 166 (0.9975247524752475, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 167 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 168 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 169 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9396551724137931, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "Epoch: 170 (1.0, tensor(1.), tensor(1.), tensor(1.)) (0.9310344827586207, tensor(0.8881), tensor(0.9535), tensor(0.8000))\n",
            "--- 57.47491240501404 seconds ---\n"
          ]
        }
      ]
    }
  ]
}